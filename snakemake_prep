@Author: Steve Wong

#Work on 06/16 and 06/20
#installed dependencies:
#Python ≥3.5
#Snakemake ≥5.24.1
#BWA 0.7
#SAMtools 1.9
#Pysam 0.15
#BCFtools 1.9
#Graphviz 2.42
#Jinja2 2.11
#NetworkX 2.5
#Matplotlib 3.3

#some basic operating commands
#activate the virtual environment
$ conda activate snakemake-tutorial
#generate snake output
$ snakemake --cores 1 {output}
#with a specified snake file
snakemake --cores 1 --snakefile {filename} {output}
#to update anything in the linux, copy file by 
$ cp -r /mnt/c/Users/zwang/wzyBest/practice_codes/Snakemake/Snakefile ~/snakemake-tutorial
#backward
$ cp -r ~/snakemake-tutorial /mnt/c/Users/zwang/wzyBest/practice_codes/Snakemake/Snakefile
#edit a file content
$ nano file
#use ctrl o to store and ctrl x to exit
#creat an empty file or update timestamp
$ touch filename
#show the content
$ cat
#Change the working permit:
$ chmod -R 777 + file






#set up the environment
#Windows Subsystem for Linux: If you use Windows 10, you can set up the Windows Subsystem for Linux (WSL) to natively run linux applications. Install the WSL following the instructions in the WSL Documentation. You can chose any Linux distribution available for the WSL, but the most popular and accessible one is Ubuntu. Start the WSL and set up your account; now, you can follow the steps of our tutorial from within your Linux environment in the WSL.

#Step 1: Installing Mambaforge
#First, please open a terminal or make sure you are logged into your Vagrant Linux VM. Assuming that you have a 64-bit system, on Linux, download and install Miniconda 3 with

$ curl -L https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-Linux-x86_64.sh -o Mambaforge-Linux-x86_64.sh
$ bash Mambaforge-Linux-x86_64.sh

#Step 2: Preparing a working directory
#First, create a new directory snakemake-tutorial at a place you can easily remember and change into that directory in your terminal:

$ mkdir snakemake-tutorial
$ cd snakemake-tutorial

#First, we download some example data on which the workflow shall be executed:

$ curl -L https://api.github.com/repos/snakemake/snakemake-tutorial-data/tarball -o snakemake-tutorial-data.tar.gz
#Next we extract the data. On Linux, run

$ tar --wildcards -xf snakemake-tutorial-data.tar.gz --strip 1 "*/data" "*/environment.yaml"
#This will create a folder data and a file environment.yaml in the working directory.

#Step 3: Creating an environment with the required software

$ conda install -n base -c conda-forge mamba

#Make sure to activate the conda base environment with

$ conda activate base
#The environment.yaml file that you have obtained with the previous step (Step 2) can be used to install all required software into an isolated Conda environment with the name snakemake-tutorial via

$ mamba env create --name snakemake-tutorial --file environment.yaml
If you don’t have the Mamba command because you used a different conda distribution than Mambaforge, you can also first install Mamba (which is a faster and more robust replacement for Conda) in your base environment with

#Step 4: Activating the environment
#To activate the snakemake-tutorial environment, execute

$ conda activate snakemake-tutorial
$ snakemake --help

#Now do actual operations in snakemake
#Step 1: Mapping reads
#Our first Snakemake rule maps reads of a given sample to a given reference genome (see Background). For this, we will use the tool bwa, specifically the subcommand bwa mem. In the working directory, create a new file called Snakefile with an editor of your choice. We propose to use the Atom editor, since it provides out-of-the-box syntax highlighting for Snakemake. In the Snakefile, define the following rule:

rule bwa_map:
    input:
        "data/genome.fa",
        "data/samples/A.fastq"
    output:
        "mapped_reads/A.bam"
    shell:
        "bwa mem {input} | samtools view -Sb - > {output}"

#A Snakemake rule has a name (here bwa_map) and a number of directives, here input, output and shell. 
#The input and output directives are followed by lists of files that are expected to be used or created by the rule. 
#The shell directive is followed by a Python string containing the shell command to execute.
#Here, we refer to the output file by specifying {output} and to the input files by specifying {input}. 
#Since the rule has multiple input files, Snakemake will concatenate them, separated by a whitespace. 
#In other words, Snakemake will replace {input} with data/genome.fa data/samples/A.fastq before executing the command. 
#The shell command invokes bwa mem with reference genome and reads, and pipes the output into samtools which creates a compressed BAM file containing the alignments.
#The output of samtools is redirected into the output file defined by the rule with >.
$ snakemake -np mapped_reads/A.bam    
#or
$ snakemake --cores 1 mapped_reads/A.bam

#note for some useful tips here: 
$ -p: print shell commands
$ -n: only show steps, don't run
$ -F: force running all steps
$ -j: run multiple jobs in parallel(discuss later)
#if you have multiple snakefiles, how to run? example.
#if you have a snakefile and a my_snakefile.smk, run my_snakefile.smk with the following line
$ snakemake --cores 1 --snakefile my_snakefile.smk mapped_reads/A.bam


#Step 2: Generalizing the read mapping rule
#Obviously, the rule will only work for a single sample with reads in the file data/samples/A.fastq. 
#However, Snakemake allows generalizing rules by using named wildcards. 
#Simply replace the A in the second input file and in the output file with the wildcard {sample}, leading to

rule bwa_map:
    input:
        "data/genome.fa",
        "data/samples/{sample}.fastq"
    output:
        "mapped_reads/{sample}.bam"
    shell:
        "bwa mem {input} | samtools view -Sb - > {output}"

#When Snakemake determines that this rule can be applied to generate a target file by replacing the wildcard {sample} in the output file with an appropriate value,
#it will propagate that value to all occurrences of {sample} in the input files and thereby determine the necessary input for the resulting job.

$ snakemake  --cores 1 mapped_reads/B.bam
#Snakemake will determine that the rule bwa_map can be applied to generate the target file by replacing the wildcard {sample} with the value B. 
#In the output of the dry-run, you will see how the wildcard value is propagated to the input files and all filenames in the shell command. 
#You can also specify multiple targets, for example:
$ snakemake  --cores 1 mapped_reads/A.bam mapped_reads/B.bam

#Some Bash magic can make this particularly handy. For example, you can alternatively compose our multiple targets in a single pass via
$ snakemake  --cores 1 mapped_reads/{A,B}.bam

#Step 3: Sorting read alignments
#For later steps, we need the read alignments in the BAM files to be sorted. This can be achieved with the samtools sort command. 
#We add the following rule beneath the bwa_map rule:

rule samtools_sort:
    input:
        "mapped_reads/{sample}.bam"
    output:
        "sorted_reads/{sample}.bam"
    shell:
        "samtools sort -T sorted_reads/{wildcards.sample} "
        "-O bam {input} > {output}"

$ snakemake --cores 1 sorted_reads/B.bam
#you will see how Snakemake wants to run first the rule bwa_map and then the rule samtools_sort to create the desired target file

#Step 4: Indexing read alignments and visualizing the DAG of jobs
#Next, we need to use samtools again to index the sorted read alignments so that we can quickly access reads by the genomic location they were mapped to.
#This can be done with the following rule:

rule samtools_index:
    input:
        "sorted_reads/{sample}.bam"
    output:
        "sorted_reads/{sample}.bam.bai"
    shell:
        "samtools index {input}"

#Executing, we create a visualization of the DAG using the dot command provided by Graphviz.
$ snakemake --dag sorted_reads/{A,B}.bam.bai | dot -Tsvg > dag.svg

#For multiple files in gene analysis
#Step 5: Calling genomic variants
#For the variant calling, Snakemake provides a helper function for collecting input files that helps us to describe the aggregation in this step. 
# in rules: expand("sorted_reads/{sample}.bam", sample=SAMPLES), i.e. ["sorted_reads/A.bam", "sorted_reads/B.bam"]

#the function is particularly useful when the pattern contains multiple wildcards. For example,
expand("sorted_reads/{sample}.{replicate}.bam", sample=SAMPLES, replicate=[0, 1])
#would create the product of all elements of SAMPLES and the list [0, 1], yielding ["sorted_reads/A.0.bam", "sorted_reads/A.1.bam", "sorted_reads/B.0.bam", "sorted_reads/B.1.bam"]

rule bcftools_call:
    input:
        fa="data/genome.fa",
        bam=expand("sorted_reads/{sample}.bam", sample=SAMPLES),
        bai=expand("sorted_reads/{sample}.bam.bai", sample=SAMPLES)
    output:
        "calls/all.vcf"
    shell:
        "bcftools mpileup -f {input.fa} {input.bam} | "
        "bcftools call -mv - > {output}"

#Step 6: Use custom scripts
#you need to create the .py file yourself
# the script logic is separated from the workflow logic 
rule plot_quals:
    input:
        "calls/all.vcf"
    output:
        "plots/quals.svg"
    script:
        "scripts/plot-quals.py"

#script
'''
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
from pysam import VariantFile

quals = [record.qual for record in VariantFile(snakemake.input[0])]
plt.hist(quals)

plt.savefig(snakemake.output[0])
'''

#work on 06/21
#Step 7 add a target rule
#Here, this means that we add a rule
#Apart from filenames, Snakemake also accepts rule names as targets if the requested rule does not have wildcards. 
#Hence, it is possible to write target rules collecting particular subsets of the desired results or all results. 
#If no target is given at the command line, Snakemake will define the first rule of the Snakefile as the target. 

rule all:
    input:
        "plots/quals.svg"
#to the top of our workflow. When executing Snakemake with
$ snakemake -n
#the execution plan for creating the file plots/quals.svg, which contains and summarizes all our results


#total workflow
SAMPLES = ["A", "B"]


rule all:
    input:
        "plots/quals.svg"


rule bwa_map:
    input:
        "data/genome.fa",
        "data/samples/{sample}.fastq"
    output:
        "mapped_reads/{sample}.bam"
    shell:
        "bwa mem {input} | samtools view -Sb - > {output}"


rule samtools_sort:
    input:
        "mapped_reads/{sample}.bam"
    output:
        "sorted_reads/{sample}.bam"
    shell:
        "samtools sort -T sorted_reads/{wildcards.sample} "
        "-O bam {input} > {output}"


rule samtools_index:
    input:
        "sorted_reads/{sample}.bam"
    output:
        "sorted_reads/{sample}.bam.bai"
    shell:
        "samtools index {input}"


rule bcftools_call:
    input:
        fa="data/genome.fa",
        bam=expand("sorted_reads/{sample}.bam", sample=SAMPLES),
        bai=expand("sorted_reads/{sample}.bam.bai", sample=SAMPLES)
    output:
        "calls/all.vcf"
    shell:
        "bcftools mpileup -f {input.fa} {input.bam} | "
        "bcftools call -mv - > {output}"


rule plot_quals:
    input:
        "calls/all.vcf"
    output:
        "plots/quals.svg"
    script:
        "scripts/plot-quals.py"

#script
'''
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
from pysam import VariantFile

quals = [record.qual for record in VariantFile(snakemake.input[0])]
plt.hist(quals)

plt.savefig(snakemake.output[0])
'''


#For some advanced features:
#specify the threads used:
#For some tools, it is advisable to use more than one thread in order to speed up the computation. 
#Snakemake can be made aware of the threads a rule needs with the threads directive.

rule bwa_map:
    input:
        "data/genome.fa",
        "data/samples/{sample}.fastq"
    output:
        "mapped_reads/{sample}.bam"
    threads: 8
    shell:
        "bwa mem -t {threads} {input} | samtools view -Sb - > {output}"

#if no threads specified, it will automatically use 1.
#In particular, the scheduler ensures that the sum of the threads of all jobs running at the same time does not exceed a given number of available CPU cores. 
#This number is given with the --cores command line argument, which is mandatory for snakemake calls that actually run the workflow. 
$ snakemake --cores 10
#If --cores is given without a number, all available cores are used.

#config file
#Often we want workflow to be customizable, so that it can easily be adapted to new data
#Config files can be written in JSON or YAML, and are used with the configfile directive. 

#config.yaml as
samples:
    A: data/samples/A.fastq
    B: data/samples/B.fastq
#instead of using the list['A','B']


#after that, remove samples and add 'sample=config' inside
rule bcftools_call:
    input:
        fa="data/genome.fa",
        bam=expand("sorted_reads/{sample}.bam", sample=config["samples"]),
        bai=expand("sorted_reads/{sample}.bam.bai", sample=config["samples"])
    output:
        "calls/all.vcf"
    shell:
        "bcftools mpileup -f {input.fa} {input.bam} | "
        "bcftools call -mv - > {output}"
